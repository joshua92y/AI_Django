from django.shortcuts import render
from django.http import JsonResponse
import os
import re
from dotenv import load_dotenv
import logging
from django.utils.safestring import mark_safe
from django.utils.html import escape
from django.views.decorators.csrf import csrf_exempt
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.docstore.document import Document
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
logger = logging.getLogger(__name__)

# Initialize LangChain components
def initialize_langchain(request):
    # Load environment variables
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    load_dotenv(dotenv_path=env_path, override=True)
    api_key = os.environ.get("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("API Key not found.")

    # Initialize LLM
    llm = ChatOpenAI(model="gpt-4o-mini")

    # Initialize Embeddings
    embeddings = OpenAIEmbeddings()

    # Sample documents for the vector store
  # 2ï¸âƒ£ PDF íŒŒì¼ ë¡œë“œ
    pdf_path = "C:/Users/Admin/Documents/ì¹´ì¹´ì˜¤í†¡ ë°›ì€ íŒŒì¼/ìƒê¶Œë¶„ì„.pdf"
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()  # langchain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    print(f"ğŸ” PDFì—ì„œ {len(pages)}ê°œì˜ í˜ì´ì§€ ë¡œë“œë¨")

    # 3ï¸âƒ£ ê¸´ ë¬¸ì„œë¥¼ chunkë¡œ ë¶„ë¦¬
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = splitter.split_documents(pages)

    print(f"ğŸ“ {len(docs)}ê°œì˜ ë¬¸ì„œ ì¡°ê°ìœ¼ë¡œ ë¶„í•  ì™„ë£Œ")


    # Create vector store
    vectorstore = FAISS.from_documents(docs, embeddings)
    retriever = vectorstore.as_retriever()

    # Get chat history from session or initialize empty
    chat_history = request.session.get('chat_history', [])
    
    # Create memory with chat history
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    # Load previous chat history into memory
    for message in chat_history:
        user_message = message.get('Human') or message.get('user')
        ai_message = message.get('AI') or message.get('ai')

        if user_message and ai_message:
            memory.chat_memory.add_user_message(user_message)
            memory.chat_memory.add_ai_message(ai_message)

    # Create prompt template
    prompt = PromptTemplate(
        input_variables=["chat_history", "context", "question"],
        template=(
            "ë‹¹ì‹ ì€ ë˜‘ë˜‘í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
            "ì°¸ê³ : {context}\n"
            "ì§ˆë¬¸: {question}\n"
            "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”:\n{chat_history}\n"
            "ë‹µë³€:"
        )
    )

    # Create QA chain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        combine_docs_chain_kwargs={"prompt": prompt},
        return_source_documents=True
    )

    return qa_chain

def format_response(text):
    # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    text = text.replace('\n', '<br>')
    
    # ì´ëª¨ì§€ ì²˜ë¦¬ (ì´ëª¨ì§€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„)
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    
    # ì´ëª¨ì§€ê°€ ìˆëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€
    if emoji_pattern.search(text):
        return mark_safe(text)
    
    # ê¸´ ë¬¸ì¥ì— ì ì ˆí•œ ì¤„ë°”ê¿ˆ ì¶”ê°€
    sentences = text.split('. ')
    formatted_text = '. <br>'.join(sentences)
    
    return mark_safe(formatted_text)

def index(request):
    return render(request, 'AItest/chat.html')

@csrf_exempt
def send(request):
    if request.method == 'POST':
        user_message = request.POST.get('message', '').strip()

        if not user_message:
            return JsonResponse({'error': 'ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.'}, status=400)

        try:
            # Initialize LangChain components with request
            qa_chain = initialize_langchain(request)

            # Get response from QA chain
            result = qa_chain.invoke({"question": user_message})
            bot_response = result['answer'].strip()

            # Update chat history in session
            chat_history = request.session.get('chat_history', [])
            chat_history.append({
                'Human': user_message,
                'AI': bot_response
            })
            request.session['chat_history'] = chat_history

            return JsonResponse({'response': format_response(bot_response)})

        except Exception as e:
            logger.error(f"Error in send view: {str(e)}", exc_info=True)
            return JsonResponse({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}, status=500)

    return JsonResponse({'error': 'ì˜ëª»ëœ ìš”ì²­ ë°©ì‹ì…ë‹ˆë‹¤.'}, status=400)
